{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "1MdRN-6b49R-",
    "outputId": "384d2bf6-de8e-42c0-c888-ce069764852b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "q2Sk50Pl884D"
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "def data_train(batch_size):\n",
    "  # MNISTの全学習データからbatch_size(int)個のデータをランダムに取り出し、\n",
    "  # 入力データをx_trainに入れ、y_trainにラベルを入れる。\n",
    "  # 入力データは784次元のベクトル、ラベルは10次元のone-hotベクトル\n",
    "  x_train, y_train = mnist.train.next_batch(batch_size)\n",
    "  \n",
    "  # 畳み込み層に入力できるように入力データを整形。\n",
    "  # 出来上がったx_train_dataは形状(batch_size, 28, 28, 1)のNumPy配列\n",
    "  # 28×28の行列で、白黒なのでチャンネル数は1。\n",
    "  x_train_data = []\n",
    "  for data in x_train:\n",
    "    x_train_data.append(np.reshape(data, (28, 28,1)))\n",
    "  x_train_data = np.array(x_train_data)\n",
    "  \n",
    "  return x_train_data, y_train\n",
    "  \n",
    "def data_test(batch_size):\n",
    "  # MNISTの全テストデータからbatch_size(int)個のデータをランダムに取り出し、\n",
    "  # 入力データをx_testに入れ、y_testにラベルを入れる。\n",
    "  # 入力データは784次元のベクトル、ラベルは10次元のone-hotベクトル\n",
    "  x_test, y_test = mnist.test.next_batch(batch_size)\n",
    "  \n",
    "  # 畳み込み層に入力できるように入力データを整形。\n",
    "  # 出来上がったx_test_dataは形状(batch_size, 28, 28, 1)のNumPy配列\n",
    "  # 28×28の行列で、白黒なのでチャンネル数は1。\n",
    "  x_test_data = []\n",
    "  for data in x_test:\n",
    "    x_test_data.append(np.reshape(data, (28, 28,1)))\n",
    "  x_test_data = np.array(x_test_data)\n",
    "  \n",
    "  return x_test_data, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "_f8WWOPyEGOy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def weight_variable(shape, name=None):\n",
    "    # 各層で使用する重み行列を返す関数\n",
    "    # 標準偏差が0.1の切断正規分布からshapeで指定された形のテンソルを生成し、initialに代入\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "\n",
    "    # 初期のテンソルがinitialの変数tf.Variableを返す\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def softmax_layer(inpt, shape):\n",
    "    # shapeで指定される形の重みをfc_wに代入\n",
    "    fc_w = weight_variable(shape)\n",
    "\n",
    "    # shape[1]で指定される形の重みをfc_bに代入\n",
    "    #初期値はゼロベクトル\n",
    "    fc_b = tf.Variable(tf.zeros([shape[1]]))\n",
    "\n",
    "    # 全結合後、ソフトマックスを計算\n",
    "    fc_h = tf.nn.softmax(tf.matmul(inpt, fc_w) + fc_b)\n",
    "\n",
    "    return fc_h\n",
    "\n",
    "def conv_layer(inpt, filter_shape, stride):\n",
    "    # 入力データのチャンネル数をinpt_channelsに代入\n",
    "    inpt_channels =  inpt.get_shape().as_list()[3]\n",
    "\n",
    "    # Batch Normalization\n",
    "    # チャンネル毎に平均meanと分散varを計算\n",
    "    mean, var = tf.nn.moments(inpt, axes=[0,1,2])\n",
    "    # Batch Normalizationに使用する学習パラメータbetaとgammaを準備\n",
    "    # betaの初期値はゼロベクトル\n",
    "    beta = tf.Variable(tf.zeros([inpt_channels]), name=\"beta\")\n",
    "    gamma = weight_variable([inpt_channels], name=\"gamma\")\n",
    "    # Batch Normalization実施\n",
    "    batch_norm = tf.nn.batch_norm_with_global_normalization(\n",
    "        inpt, mean, var, beta, gamma, 0.001,\n",
    "        scale_after_normalization=True)\n",
    "\n",
    "    # 活性化関数としてReLU関数使用\n",
    "    out_relu = tf.nn.relu(batch_norm)\n",
    "\n",
    "    # 畳み込み層\n",
    "    # filter_shapeで指定される形の重みをfilter_に代入\n",
    "    filter_ = weight_variable(filter_shape)\n",
    "    # 畳み込み層の出力をoutに代入\n",
    "    out = tf.nn.conv2d(out_relu, filter=filter_, strides=[1, stride, stride, 1], padding=\"SAME\")\n",
    "\n",
    "    return out\n",
    "\n",
    "def residual_block(inpt, output_depth, stride=1, projection=False):\n",
    "    # 入力データのチャンネル数をinput_depthに代入\n",
    "    input_depth = inpt.get_shape().as_list()[3]\n",
    "\n",
    "    # Batch Normalization + Relu +畳み込みを3セット\n",
    "    conv1 = conv_layer(inpt, [1, 1, input_depth, int(output_depth/4)], stride)\n",
    "    conv2 = conv_layer(conv1, [3, 3, int(output_depth/4), int(output_depth/4)], stride)\n",
    "    conv3 = conv_layer(conv2, [1, 1, int(output_depth/4), output_depth], stride)\n",
    "\n",
    "    # 入力と出力のチャンネル数が異なる場合は以下の2つの方法でチャンネル数を揃える\n",
    "    if input_depth != output_depth:\n",
    "        if projection:\n",
    "            # Option B: Projection shortcut\n",
    "            input_layer = conv_layer(inpt, [1, 1, input_depth, output_depth], 2)\n",
    "        else:\n",
    "            # Option A: Zero-padding\n",
    "            # 足りない部分を0でパディング\n",
    "            input_layer = tf.pad(inpt, [[0,0], [0,0], [0,0], [0, output_depth - input_depth]])\n",
    "    else:\n",
    "        input_layer = inpt\n",
    "\n",
    "    # conv3に入力を足す\n",
    "    res = conv3 + input_layer\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "72X47_pdEPdF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# from resnet import softmax_layer, conv_layer, residual_block\n",
    "\n",
    "def resnet(inpt):\n",
    "    \n",
    "    layers = []\n",
    "\n",
    "    # Residual Blockに入る前に1つ畳み込み層とmax poolingを通す\n",
    "    with tf.variable_scope('conv1'):\n",
    "        conv1 = conv_layer(inpt, [7, 7, 1, 16], 1)\n",
    "        max_pooling = tf.nn.max_pool(conv1, [1, 3, 3, 1], [1, 1, 1, 1], padding=\"SAME\")\n",
    "        layers.append(conv1)\n",
    "        layers.append(max_pooling)\n",
    "      \n",
    "    # residual blockの総数は3個\n",
    "    # 出力のshapeは[batch_size, 28, 28, 16]\n",
    "    with tf.variable_scope('conv2'):\n",
    "        conv2_1 = residual_block(layers[-1], 16)\n",
    "        conv2_2 = residual_block(conv2_1, 16)\n",
    "        conv2_3 = residual_block(conv2_2, 16)\n",
    "        layers.append(conv2_1)\n",
    "        layers.append(conv2_2)\n",
    "        layers.append(conv2_3)\n",
    "\n",
    "    assert conv2_3.get_shape().as_list()[1:] == [28, 28, 16]\n",
    "\n",
    "    # residual blockの総数は4個\n",
    "    # 出力のshapeは[batch_size, 28, 28, 32]\n",
    "    with tf.variable_scope('conv3'):\n",
    "        conv3_1 = residual_block(layers[-1], 32, stride=1)\n",
    "        conv3_2 = residual_block(conv3_1, 32)\n",
    "        conv3_3 = residual_block(conv3_2, 32)\n",
    "        conv3_4 = residual_block(conv3_3, 32)\n",
    "        layers.append(conv3_1)\n",
    "        layers.append(conv3_2)\n",
    "        layers.append(conv3_3)\n",
    "        layers.append(conv3_4)\n",
    "\n",
    "    assert conv3_4.get_shape().as_list()[1:] == [28, 28, 32]\n",
    "    \n",
    "    # residual blockの総数は6個\n",
    "    # 出力のshapeは[batch_size, 28, 28, 64]\n",
    "    with tf.variable_scope('conv4'):\n",
    "        conv4_1 = residual_block(layers[-1], 64, stride=1)\n",
    "        conv4_2 = residual_block(conv4_1, 64)\n",
    "        conv4_3 = residual_block(conv4_2, 64)\n",
    "        conv4_4 = residual_block(conv4_3, 64)\n",
    "        conv4_5 = residual_block(conv4_4, 64)\n",
    "        conv4_6 = residual_block(conv4_5, 64)\n",
    "        layers.append(conv4_1)\n",
    "        layers.append(conv4_2)\n",
    "        layers.append(conv4_3)\n",
    "        layers.append(conv4_4)\n",
    "        layers.append(conv4_5)\n",
    "        layers.append(conv4_6)\n",
    "\n",
    "    assert conv4_6.get_shape().as_list()[1:] == [28, 28, 64]\n",
    "    \n",
    "    # residual blockの総数は3個\n",
    "    # 出力のshapeは[batch_size, 28, 28, 128]\n",
    "    with tf.variable_scope('conv5'):\n",
    "        conv5_1 = residual_block(layers[-1], 128, stride=1)\n",
    "        conv5_2 = residual_block(conv5_1, 128)\n",
    "        conv5_3 = residual_block(conv5_2, 128)\n",
    "        layers.append(conv5_1)\n",
    "        layers.append(conv5_2)\n",
    "        layers.append(conv5_3)\n",
    "\n",
    "    assert conv5_3.get_shape().as_list()[1:] == [28, 28, 128]\n",
    "\n",
    "    with tf.variable_scope('fc'):\n",
    "        # batch_sizeとチャンネル数毎に平均をとる\n",
    "        global_pool = tf.reduce_mean(layers[-1], [1, 2])\n",
    "        \n",
    "        assert global_pool.get_shape().as_list()[1:] == [128]\n",
    "        \n",
    "        # 全結合+ソフトマックス\n",
    "        out = softmax_layer(global_pool, [128, 10])\n",
    "        layers.append(out)\n",
    "\n",
    "    return layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "3LS1q8e0EQS8"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    batch_size = 128\n",
    "\n",
    "    X = tf.placeholder(\"float\", [batch_size, 28, 28, 1])\n",
    "    Y = tf.placeholder(\"float\", [batch_size, 10])\n",
    "    learning_rate = tf.placeholder(\"float\", [])\n",
    "\n",
    "    # ResNet\n",
    "    net = resnet(X)\n",
    "\n",
    "    cross_entropy = -tf.reduce_sum(Y*tf.log(net))\n",
    "    opt = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
    "    train_op = opt.minimize(cross_entropy)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(net, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    train_step_num = int(55000 / batch_size)\n",
    "    test_step_num = int(10000 / batch_size)   \n",
    "    epoch_num = 10\n",
    "\n",
    "    # 学習\n",
    "    for j in range (epoch_num):\n",
    "        for i in range(train_step_num):\n",
    "            x_train, y_train = data_train(batch_size)\n",
    "            feed_dict={\n",
    "                X: x_train, \n",
    "                Y: y_train,\n",
    "                learning_rate: 0.001}\n",
    "            sess.run([train_op], feed_dict=feed_dict)\n",
    "\n",
    "    # テスト\n",
    "    accs = []\n",
    "    for j in range (epoch_num):\n",
    "        for i in range(test_step_num):\n",
    "            x_test, y_test = data_test(batch_size)\n",
    "            acc = sess.run([accuracy],feed_dict={\n",
    "                X: x_test,\n",
    "                Y: y_test\n",
    "            })\n",
    "            accuracy_summary = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "            accs.append(acc[0])\n",
    "\n",
    "    sess.close()\n",
    "\n",
    "    return sum(accs)/len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "oqHYx_cwV8AY",
    "outputId": "ec05de7d-f784-4b23-9022-63f6dc2cdbaa"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "acc = main()\n",
    "print('精度 : ' + str(acc))\n",
    "print('時間 : ' + str(time.time() - start) + 's')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Resnet.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
